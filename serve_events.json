[
  {
    "category": "Registration",
    "channel_url": "",
    "day": "1",
    "description": "Time to register at ISMIR2025!",
    "end_time": "9:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-21",
    "start_time": "8:00",
    "title": "Registration",
    "uid": "1",
    "web_link": ""
  },
  {
    "category": "Tutorials",
    "channel_url": "https://ismir2025workspace.slack.com/archives/C09CRFBPCFP",
    "day": "1",
    "description": "Recent years have witnessed growing interest in bridging traditional sound synthesis methods with emerging machine learning technologies. This tutorial is motivated by the convergence of two previously distinct trajectories in audio research: physics-based sound synthesis and data-driven neural approaches. This session highlights how differentiable physical modeling opens new avenues for musical sound synthesis by combining the interpretability and realism of physical simulation with the learning capacity of modern neural networks. The tutorial is structured into five segments: an overview of digital synthesis history and physical modeling, a detailed introduction to finite difference time domain (FDTD) methods across various instrument classes, a broad survey of neural architectures relevant to physical modeling, an in-depth look at differentiable modeling for parameter estimation using automatic differentiation, and a concluding session to synthesize key takeaways. Attendees will engage with theoretical material, practical demonstrations, and programming exercises, gaining hands-on experience in combining physics-based simulation with neural networks. This tutorial is designed for researchers and engineers interested in advanced sound synthesis, particularly those working in musical acoustics, AI-based audio modeling, or digital instrument design. It will benefit individuals seeking to build physically plausible audio models or hybrid machine learning systems for realistic sound generation. All ISMIR members are warmly encouraged to attend\u2014whether newcomers or seasoned researchers. The tutorial is designed to be approachable rather than overly technical, while still offering a deep understanding of how differentiable simulation can enhance synthesis fidelity, support neural network training, and advance hybrid sound modeling.",
    "end_time": "12:30",
    "image": "",
    "organiser": "Jin Woo Lee, Stefan Bilbao, and Rodrigo Diaz",
    "organiser_affiliation": "",
    "organiser_bio": "<b>Jin Woo Lee</b> is currently a Postdoctoral Associate at Massachusetts Institute of Technology (MIT). He received his PhD degree from Seoul National University, with a thesis entitled \"Physical Modeling for String Instrument Sound Synthesis based on Finite-difference Scheme and Automatic Differentiation\". His research interest is mainly focused on machine learning, physical modeling, and numerical simulation, involving audio, music, speech, and acoustics. His works have been presented at conferences such as NeurIPS, ICASSP, Interspeech, and WASPAA, as well as invited talks at Stanford CCRMA and the University of Iowa. Previously, he worked at Meta and Supertone as an intern, and at Gaudio Lab as an AI Scientist. <br><br> <b>Stefan Bilbao</b> (B.A. Physics, Harvard, 1992, MSc., PhD Electrical Engineering, Stanford, 1996 and 2001 respectively) is currently Professor of Acoustics and Audio Signal Processing in the Acoustics and Audio Group at the University of Edinburgh, and previously held positions at the Sonic Arts Research Centre, at the Queen's University Belfast, and the Stanford Space Telecommunications and Radioscience Laboratory. He led the ERC-funded NESS and WRAM projects between 2012 and 2018. He is an Associate Editor of JASA Express Letters, and a Senior Area Editor of the IEEE Open Journal of Signal Processing, and was previously an associate editor of the IEEE/ACM Transactions on Audio Speech and Language Processing. He was awarded the Foreign medal of the French Acoustical Society in 2022. He works primarily on problems in acoustic simulation and audio signal processing for sound synthesis and room acoustics applications. He was born in Montreal, Quebec, Canada. <br><br> <b>Rodrigo Diaz</b> is a PhD candidate in Artificial Intelligence and Music at Queen Mary University of London, under the supervision of Prof. Mark Sandler and Dr. Charalampos Saitis. His research focuses on real-time audio synthesis using neural networks and physics-based modelling. His work has been presented at conferences across the audio and computer vision communities, including CVPR, ICASSP, IC3D, DAFx, and AES. Before his PhD, he worked as a researcher at the Fraunhofer HHI Institute in Berlin, exploring volumetric reconstruction from images using neural networks.",
    "organiser_emails": "jinwlee@snu.ac.kr, s.bilbao@ed.ac.uk, r.diazfernandez@qmul.ac.uk",
    "slack_channel": "t1-differentiable-physical-modeling",
    "start_date": "2025-09-21",
    "start_time": "9:00",
    "title": "T1(M): Differentiable Physical Modeling Sound Synthesis: Theory, Musical Application, and Programming",
    "uid": "2",
    "web_link": ""
  },
  {
    "category": "Tutorials",
    "channel_url": "https://ismir2025workspace.slack.com/archives/C09CU44AMML",
    "day": "1",
    "description": "Differentiable digital signal processing is a technique in which signal processing algorithms are implemented as differentiable programs used in combination with deep neural networks. The advantages of this methodology include a reduction in model complexity, lower data requirements, and an inherently interpretible intermediate representation. In recent years, differentiable audio synthesizers have been applied to a variety of tasks, including voice and instrument modelling, synthesizer control, pitch estimation, source separation, and parameter estimation. Yet despite the growing popularity of such methods, the implementation of differentiable audio synthesizers remains poorly documented, and the simple formulation of many synthesizers belies their complex optimization behaviour. To address this gap, this tutorial offers an introduction to the fundamentals of differentiable synthesizer programming.",
    "end_time": "12:30",
    "image": "",
    "organiser": "Julien Guinot, Alain Riou, Yuexuan Kong, Marco Pasini, Gabriel Meseguer-Brocal, Stefan Lattner",
    "organiser_affiliation": "",
    "organiser_bio": "<b>Julien Guinot</b> is a second-year PhD student at the AI and Music Centre for Doctoral Training at Queen Mary University of London, Sponsored By Universal Music Group, under the supervision of Dr. Gy\u00f6rgy Fazekas, Dr. Emmanouil Benetos, and Dr. Elio Quinton. His research interests include representation learning for music, with a focus on improving representations and (multimodal) SSL approaches for user-centric applications such as controllable retrieval. Previously, his work on contrastive learning for music representations has been accepted and presented at ISMIR and ICASSP.<br><br><b>Alain Riou</b> is recent PhD graduate previously working on self-supervised learning of musical representations at T\u00e9l\u00e9com Paris and Sony CSL - Paris, under the supervision of Stefan Lattner, Ga\u00ebtan Hadjeres, and Geoffroy Peeters. His main research interests are related to deep representation learning, with a strong focus on self-supervised methods for music information retrieval. His work \"PESTO: Pitch Estimation with Self-supervised Transposition-equivariant Objective\" received the Best Paper Award at ISMIR 2023. His recent work on JEPA models applied to music has been accepted at ISMIR and ICASSP.<br><br><b>Yuexuan Kong</b> is a second-year industrial PhD student at Deezer, and a research unit named LS2N of CNRS (the French national center for scientific research) at Ecole Centrale de Nantes, under the supervision of Dr. Gabriel Meseguer-Brocal, Dr. Vincent Lostanlen, Dr. Mathieu Lagrange and Dr. Romain Hennequin. Her research focus on self-supervised learning applied in music, notably equivariant self-supervised learning and contrastive learning.<br><br><b>Marco Pasini</b> is a second-year PhD student at Queen Mary University of London, in collaboration with Sony Computer Science Laboratories - Paris. He is passionate about the field of Generative Modeling, especially when applied to the audio domain. He previously worked on models such as Musika for fast music generation, the Music2Latent series of models for efficient audio compression, Diff-A-Riff for accompaniment generation, and the Continuous Autoregressive Models generative framework.<br><br><b>Gabriel Meseguer-Brocal</b> is a research scientist at Deezer with over two years of experience at the company. Before joining Deezer, he completed postdoctoral research at Centre National de la Recherche Scientifique (CNRS) in France. In 2020, he earned his Ph.D. in Computer Science, Telecommunications, and Electronics with a focus on the Sciences & Technologies of Music and Sound at IRCAM. His research interests include signal processing and deep learning techniques for music processing, with a focus on areas such as source separation, dataset creation, multi-tagging, self-supervised learning, and multimodal analysis.<br><br><b>Stefan Lattner</b> serves as a research leader at the music team at Sony CSL - Paris, where he focuses on generative AI for music production, music information retrieval, and computational music perception. He earned his PhD in 2019 from Johannes Kepler University (JKU) in Linz, Austria, following his research at the Austrian Research Institute for Artificial Intelligence in Vienna and the Institute of Computational Perception Linz. His studies centered on the modeling of musical structure, encompassing transformation learning and computational relative pitch perception. His current interests include human-computer interaction in music creation, live staging, and information theory in music. He specializes in generative sequence models, computational short-term memories, (self-supervised) representation learning, and musical audio generation. In 2019, he received the Best Paper Award at ISMIR for his work, \"Learning Complex Basis Functions for Invariant Representations of Audio\".",
    "organiser_emails": "j.guinot@qmul.ac.uk, alain.riou@sony.com, ykong@deezer.com, m.pasini@qmul.ac.uk, gmeseguerbrocal@deezer.com, me@stefanlattner.at",
    "slack_channel": "t2-self-supervised-learning",
    "start_date": "2025-09-21",
    "start_time": "9:00",
    "title": "T2(M): Self-supervised Learning for Music - An Overview and New Horizons",
    "uid": "3",
    "web_link": ""
  },
  {
    "category": "Tutorials",
    "channel_url": "https://ismir2025workspace.slack.com/archives/C09CDLC7W4X",
    "day": "1",
    "description": "With the rise of the attention mechanism and the success of auto-regressive generative modelling and large language models, the Transformer architecture has arguably been the most promising technology for symbolic music generation. While audio-based methods have shown promise, symbolic music generation offers distinct advantages in terms of control, long-term coherence and computational efficiency. This tutorial explores the potential of the Transformer architecture in symbolic music generation and aims to provide (1) a thorough understanding of the vanilla Transformer architecture (emphasising the reasoning behind its design choices) and the utilisation of large language models for symbolic music generation. Additionally, it offers (2) a comprehensive overview of the field, including a taxonomy and a curated list of valuable datasets. The tutorial delves into (3) an in-depth analysis of Transformer variants and large language models specifically tailored for symbolic music generation. Also, it examines (4) examples and advanced considerations such as style, musical conditioning, and real-time performance. Furthermore, the tutorial offers (5) two hands-on exercises using Google Colab Notebooks, enabling participants to apply the concepts covered. Overall, this tutorial equips participants with the theoretical knowledge and practical skills necessary to explore the power of the Transformer architecture in symbolic music generation.",
    "end_time": "12:30",
    "image": "",
    "organiser": "Peter Harrison, Harin Lee, Manuel Anglada-Tort, Pol van Rijn, Nori Jacoby",
    "organiser_affiliation": "",
    "organiser_bio": "<b>Peter Harrison</b> is an Assistant Professor at the Faculty of Music, University of Cambridge, where he directs the Centre for Music and Science. He completed his PhD with Marcus Pearce at Queen Mary University of London, and his postdoc with Nori Jacoby at the Max Planck Institute for Empirical Aesthetics. His research involves building and evaluating computational models of music cognition, seeking to understand how humans perceive and produce music. He also develops methodologies to support such research, including software platforms for running online experiments (PsyNet, psychTestR) and test batteries for assessing individual musical capacities.<br><br><b>Harin Lee</b> is a PhD candidate at the Max Planck Institute for Human Cognitive and Brain Science under the supervision of Marc Sch\u00f6nwiesner and co-supervised by Nori Jacoby at the Computational Auditory Perception Group, Max Planck Institute for Empirical Aesthetics. His interests concern cross-cultural diversity in music and its quantitative analysis. He combines datasets of music around the world with large-scale behavioral experiments and causal modeling to tackle questions about inter-individual and cross-cultural differences in music cognition.<br><br><b>Manuel Anglada-Tort</b> is a Lecturer in the Department of Psychology at Goldsmiths, University of London, and co-director of the Music, Mind, and Brain Group. He completed a PhD on Music Cognition at the Technische Universit\u00e4t Berlin and a postdoc at the Max Planck Institute for Empirical Aesthetics. His work combines computational methods and large-scale behavioural experiments to study the cognitive and cultural foundations of music, creativity, and aesthetics.<br><br><b>Pol van Rijn</b> is a PhD candidate at the Max Planck Institute for Empirical Aesthetics, supervised by Nori Jacoby. His research combines corpus work and large-scale behavioral experiments to investigate the mapping between speech prosody and emotion.<br><br><b>Nori Jacoby</b> is an assistant professor in the Department of Psychology at Cornell University. His research focuses on the internal representations that support and shape our sensory and cognitive abilities, and on how those representations are themselves determined by both nature and nurture. He addresses these classic issues with new tools, both by applying machine learning techniques to behavioral experiments, and by expanding the scale and scope of experimental research via massive online experiments and fieldwork in locations around the globe.",
    "organiser_emails": "pmch2@cam.ac.uk, harin.lee@ae.mpg.de, M.AngladaTort@gold.ac.uk",
    "slack_channel": "t3-psynet-online-research",
    "start_date": "2025-09-21",
    "start_time": "9:00",
    "title": "T3(M): PsyNet: Online Research Platform for Music Studies",
    "uid": "4",
    "web_link": ""
  },
  {
    "category": "Lunch",
    "channel_url": "",
    "day": "1",
    "description": "",
    "end_time": "14:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-21",
    "start_time": "13:00",
    "title": "Lunch",
    "uid": "5",
    "web_link": ""
  },
  {
    "category": "Tutorials",
    "channel_url": "https://ismir2025workspace.slack.com/archives/C09CU4682TG",
    "day": "1",
    "description": "A core strategy in Music Information Retrieval (MIR) is to use mid-level representations to connect and analyze music-related information across different domains. For example, these representations help link audio recordings to symbolic data such as pitches, chords, and lyrics. While traditional MIR approaches relied on expert knowledge to design these representations, recent advances in deep learning have made it possible to learn them directly from annotated data. This shift has led to major progress in tasks such as music transcription, chord recognition, pitch tracking, version identification, and lyrics alignment. A key challenge in training deep learning models for these tasks is the limited availability of strongly aligned datasets, which provide detailed frame-level annotations but are costly and time-consuming to produce. In contrast, weakly aligned data offers only coarse segment-level correspondences, making it easier to collect but harder to use with standard training methods. This tutorial addresses the problem by introducing differentiable alignment techniques, which enable models to learn from weakly aligned data using alignment-aware and fully differentiable loss functions. We begin with an intuitive overview of classical methods such as Dynamic Time Warping (DTW), followed by differentiable alternatives like Soft-DTW and Connectionist Temporal Classification (CTC) loss. The tutorial also introduces key concepts such as convex optimization and gradient computation, which are essential for integrating these methods into end-to-end learning systems. Applications in MIR are illustrated through case studies including multi-pitch estimation, transcription, score-audio alignment, and cross-version retrieval. This tutorial is intended for a broad audience and emphasizes both conceptual clarity and practical relevance. It equips participants with a solid understanding of how differentiable alignment techniques enable the training of deep models using weakly or partially aligned data. These methods are becoming increasingly important in MIR and other domains involving time-based multimedia data.",
    "end_time": "17:30",
    "image": "",
    "organiser": "Meinard M\u00fcller, Johannes Zeitler",
    "organiser_affiliation": "",
    "organiser_bio": "<b>Meinard M\u00fcller</b> received the Diploma degree (1997) in mathematics and the Ph.D. degree (2001) in computer science from the University of Bonn, Germany. Since 2012, he has held a professorship for Semantic Audio Signal Processing at the International Audio Laboratories Erlangen, a joint institute of the Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg (FAU) and the Fraunhofer Institute for Integrated Circuits IIS. His recent research interests include music processing, music information retrieval, audio signal processing, and motion processing. He was a member of the IEEE Audio and Acoustic Signal Processing Technical Committee (2010-2015), a member of the Senior Editorial Board of the IEEE Signal Processing Magazine (2018-2022), and a member of the Board of Directors, International Society for Music Information Retrieval (2009-2021, being its president in 2020/2021). In 2020, he was elevated to IEEE Fellow for contributions to music signal processing. Currently, he also serves as Editor-in-Chief for the Transactions of the International Society for Music Information Retrieval (TISMIR). Besides his scientific research, Meinard M\u00fcller has been very active in teaching music and audio processing. He gave numerous tutorials at major conferences, including ICASSP (2009, 2011, 2019) and ISMIR (2007, 2010, 2011, 2014, 2017, 2019, 2023, 2024). Furthermore, he wrote a monograph titled \"Information Retrieval for Music and Motion\" (Springer 2007) as well as a textbook titled \"Fundamentals of Music Processing\" (Springer-Verlag 2015).<br><br><b>Johannes Zeitler</b> received his B.Sc. degree in Electrical Engineering and his M.Sc. degree in Signal Processing and Communications Engineering from Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, Germany, in 2019 and 2021, respectively. In 2022, he joined the International Audio Laboratories Erlangen, where he is currently pursuing his Ph.D. under the supervision of Prof. Meinard M\u00fcller. His research interests include alignment techniques in music processing.",
    "organiser_emails": "meinard.mueller@audiolabs-erlangen.de, johannes.zeitler@audiolabs-erlangen.de",
    "slack_channel": "t4-differentiable-alignment-techniques",
    "start_date": "2025-09-21",
    "start_time": "14:30",
    "title": "T4(A): Differentiable Alignment Techniques for Music Processing: Techniques and Applications",
    "uid": "6",
    "web_link": ""
  },
  {
    "category": "Tutorials",
    "channel_url": "https://ismir2025workspace.slack.com/archives/C09CXV0DDRS",
    "day": "1",
    "description": "This tutorial addresses the growing need to understand the decision-making processes of Artificial Intelligence (AI) systems with Deep Learning (DL) in the sound and music domain. As DL models continue to achieve state-of-the-art performance in music recognition, generation, and analysis, their lack of transparency poses a significant challenge for evaluating trained models and gaining insights from them. In response, explainable AI (XAI) techniques have emerged as a crucial tool for interpreting and understanding the behavior of complex DL models. However, the application of XAI in music is still a relatively underexplored area. This tutorial aims to bridge this gap by providing a comprehensive introduction to XAI methodologies and their application in the music domain. Through a combination of theoretical foundations and practical exercises, participants will gain a deeper understanding of XAI techniques and their potential to enhance the interpretability and transparency of DL models in music. The tutorial will cover the current state of XAI in music, discuss challenges and opportunities, and provide hands-on experience with applying XAI techniques to real-world music use cases. This tutorial is suitable for researchers and practitioners looking to expand their skills in XAI and its applications in music. A basic understanding of DL concepts is recommended, but no prior experience with XAI is required. For the practical exercises, prior knowledge of Python and PyTorch is beneficial.",
    "end_time": "17:30",
    "image": "",
    "organiser": "Valerie Krug, Maral Ebrahimzadeh, Tia Bolle, Jan-Ole Perschewski, Sebastian Stober",
    "organiser_affiliation": "",
    "organiser_bio": "<b>Valerie Krug</b> is postdoctoral researcher and lecturer at the Artificial Intelligence Lab at the Otto von Guericke University Magdeburg, Germany. She has a background in natural and computer sciences and earned her PhD in the field of explainable AI in 2024. Valerie develops techniques to analyze and visualize how deep neural networks perform their tasks, including novel methods that are inspired by cognitive neuroscience. Her work is driven by the aim to help humans and AI to understand each other better.<br><br><b>Maral Ebrahimzadeh</b> is a PhD researcher and lecturer at the Artificial Intelligence Lab at the Otto von Guericke University Magdeburg, Germany. Her current research focuses on exploring and investigating approaches for conditional symbolic music generation. She is also interested in exploring practical applications in gaming by leveraging both symbolic music and musical signal features. Maral earned her Master's degree in Artificial Intelligence from Iran University of Science and Technology (IUST), where she conducted research on music fingerprinting at the Audio and Speech Processing Lab.<br><br><b>Tia Bolle</b> is a master's student in computer science and student assistant at the Artificial Intelligence Lab at the Otto von Guericke University Magdeburg, Germany. Tia is a music enthusiast and produces music themselves and with a local band. The focus of their research lies in AI in creative processes and privacy/security. Tia also participated in the AI Song Contest in 2023. Their main instrument is the electric bass.<br><br><b>Jan-Ole Perschewski</b> is a PhD researcher at the Artificial Intelligence Lab at the Otto von Guericke University Magdeburg, Germany. He researches on how to find interesting projections to increase performance and understandability of deep neural networks.<br><br><b>Sebastian Stober</b> is professor for Artificial Intelligence at the Otto von Guericke University Magdeburg, Germany. He received his PhD on the topic of adaptive methods for user-centered organization of music collections in 2011. From 2013 to 2015, he was postdoctoral fellow at the Brain and Mind Institute in London, Ontario where he pioneered deep learning techniques for studying brain activity during music perception and imagination. Afterwards, he was head of the Machine Learning in Cognitive Science Lab at the University of Potsdam, before returning to Magdeburg in 2018. In his current research, he investigates and develops generative models for music and speech as well as methods to better understand what an AI has learned and how it solves specific problems. To this end, he combines the fields of AI and machine learning with cognitive neuroscience and music information retrieval. Sebastian has been active in the field of Music Information Retrieval since 2006 - for instance as co-organizer for several international workshops on Learning Semantics of Audio Signals (LSAS 2006-2009) and Adaptive Multimedia Retrieval (AMR 2007-2012) as well as the monthly Berlin Music Information Retrieval Meetup (2017-2020).",
    "organiser_emails": "valerie.krug@ovgu.de, maral.ebrahimzadeh@ovgu.de, tia.bolle@ovgu.de, jan-ole.perschewski@ovgu.de, stober@ovgu.de",
    "slack_channel": "t5-explainable-ai-for",
    "start_date": "2025-09-21",
    "start_time": "14:30",
    "title": "T5(A): Explainable AI for Music Information Retrieval",
    "uid": "7",
    "web_link": ""
  },
  {
    "category": "Tutorials",
    "channel_url": "https://ismir2025workspace.slack.com/archives/C09CRFJ0S3X",
    "day": "1",
    "description": "This tutorial provides an overview of emerging opportunities to develop and employ methods from Music Information Research for music, health, medicine and wellbeing. Music-based interventions are gaining recognition as a fertile domain for research, alongside rapidly growing developments in music technology to support music's affordances for health and well-being. We provide an overview and introduction for the MIR community to the potential contributions of computational methods to this field. The tutorial introduces examples of existing research and shows avenues for future directions, employing MIR's rich tradition of computational analysis of musical structures in different health settings. The three parts of the tutorial provide an overview on the topics of: <br><br> (1) MIR for Music Therapy (e.g. technologies for analyzing musical structures from clinical improvisations; for generating music targeting specific therapeutic functions; for supporting music-based training in between therapy sessions at home) (2) MIR in Music Heart Theranostics (use of music in digital therapeutics and precision diagnostics for cardiovascular health and disease; data and software tools for music and cardiovascular signals); (3) Neurology and Music Information in Epilepsy Research (e.g. studying music & neurology in clinical settings; joint analysis of iEEG and music features; biomarkers of music processing in iEEG). <br><br> We reflect on the potential of MIR to support research into the effectiveness of music in the health context, employing computational analysis of musical, physiological, and behavioural data in researching underlying mechanisms of music interventions. The tutorial offers connections between established MIR topics (such as audio signal processing, symbolic music processing, pattern detection), and their applications in healthcare through interdisciplinary collaborations between MIR, music cognition, neuroscience, musicology, medicine, music therapy, and related fields. We keep the technical details at an introductory level and expect the tutorial to be suitable for established and new MIR researchers.",
    "end_time": "17:30",
    "image": "",
    "organiser": "Anja Volk, Elaine Chew, Michael A. Casey",
    "organiser_affiliation": "",
    "organiser_bio": "<b>Anja Volk</b> is Professor of Music Information Computing at Utrecht University, her research aims at enhancing our understanding of music as a fundamental human trait while applying these insights for developing music technologies that offer new ways of interacting with music. Her research comprises a broad spectrum of research questions from theoretical to technology-related issues, engaging areas such as computational music analysis, computational musicology, mathematical music theory, music cognition, and music technology for health, wellbeing and inclusion. She is committed to connecting different research communities and providing interdisciplinary education for the next generation through the organization of international workshops, such as Lorentz Center in Leiden workshops on music similarity, computational ethnomusicology, and music, computing, and health. She has co-founded several international initiatives, most notably the International Society for Mathematics and Computation in Music (SMCM), the international WIMIR mentoring program, and the flagship journal of the International Society for Music Information Retrieval (TISMIR).<br><br><b>Elaine Chew</b> is Professor of Engineering at King's College London, with equal joint appointments in the Department of Engineering and School of Biomedical Engineering & Imaging Sciences. An operations researcher and pianist by training, Elaine is a pioneering researcher in MIR, focussing on mathematical representations and computational techniques for decoding musical structures. She is forging new paths at the intersection of music and cardiovascular science, applying MIR techniques to music-heart-brain interaction and computational arrhythmia research. She founded the Music Theranostics Lab at King's, where she directs research on music-based digital therapeutics and precision diagnostics. Her research has been recognised by the ERC, PECASE, NSF CAREER, (Harvard) Radcliffe Institute for Advanced Study, and the Falling Walls Science Breakthrough 2023 (Art & Science) Award.<br><br><b>Michael Casey</b> is the Francis and Mildred Sears Professor in Computer Science and Music at Dartmouth, USA. Fusing MIR, neuroimaging (fMRI, ECoG), and music theory, his research explores MIR-based methods (recommender and generative systems) to create listening programs for patients with neurological disorders. He is working with multiple hospitals (Dartmouth-Hitchcock and Amherst Medical Center) to create individualized music therapies for epilepsy patients implanted with responsive neurostimulation (RNS) devices-thereby enabling possibilities for synchronized brain data collection and neuro-responsive music therapy. Funding for his research has been awarded by the National Science Foundation (NSF), the Mellon Foundation, the National Endowment for the Humanities (NEH), the Neukom Institute for Computational Science, industry, and the Engineering and Physical Sciences Research Council (EPSRC, UK).",
    "organiser_emails": "A.Volk@uu.nl, Elaine Chew, Michael A. Casey",
    "slack_channel": "t6-mir-for-health",
    "start_date": "2025-09-21",
    "start_time": "14:30",
    "title": "T6(A): MIR for Health, Medicine, and Well-being",
    "uid": "8",
    "web_link": ""
  },
  {
    "category": "Social",
    "channel_url": "",
    "day": "1",
    "description": "",
    "end_time": "21:30",
    "image": "",
    "organiser": "ISMIR 2025 committee",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-21",
    "start_time": "18:30",
    "title": "Welcome Reception",
    "uid": "9",
    "web_link": ""
  },
  {
    "category": "Registration",
    "channel_url": "",
    "day": "2",
    "description": "Time to register at ISMIR2025!",
    "end_time": "8:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "8:00",
    "title": "Registration",
    "uid": "10",
    "web_link": ""
  },
  {
    "category": "Opening",
    "channel_url": "",
    "day": "2",
    "description": "Opening Session",
    "end_time": "9:00",
    "image": "",
    "organiser": "Session chair: opening session chair",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "8:30",
    "title": "Opening Session",
    "uid": "11",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "2",
    "description": "",
    "end_time": "10:30",
    "image": "",
    "organiser": "Session Chair: Session Chair Paper Session 1",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "9:00",
    "title": "Oral Session - 1",
    "uid": "12",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "2",
    "description": "",
    "end_time": "12:00",
    "image": "",
    "organiser": "Session Chair: Session Chair Paper Session 1",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "10:30",
    "title": "coffee + Poster Session - 1",
    "uid": "13",
    "web_link": ""
  },
  {
    "category": "Lunch",
    "channel_url": "",
    "day": "2",
    "description": "",
    "end_time": "13:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "12:00",
    "title": "Lunch",
    "uid": "14",
    "web_link": ""
  },
  {
    "category": "All Meeting",
    "channel_url": "",
    "day": "2",
    "description": "This keynote addresses the significance and future vision of the convergence of culture and technology in driving the global growth of K-Pop. The speaker, founder of SM Entertainment and A2O Entertainment, pioneered the concept of \"<b>Culture Technology (CT)</b>\", which has served as the foundation for the worldwide spread of Korean popular culture. CT systematized the entire value chain\u2014from artist discovery and training to content production and distribution\u2014establishing a framework for artist and IP creation that enabled the rise of K-Pop, while also integrating emerging technologies into music and content to transform the entertainment industry. Through \"<b>Zalpha Pop</b>,\" the speaker envisions a world where humanity connects beyond borders and languages, and foresees the emergence of a prosumer-driven ecosystem in which fans actively participate as creators rather than remaining passive consumers. In a future where artificial intelligence and other advanced technologies accelerate the transformation of the entertainment landscape, CT will serve as a catalyst to amplify human creativity and as the cornerstone of a culturally enriched future where culture and technology thrive in harmony.",
    "end_time": "14:00",
    "image": "soo-man_lee.jpg",
    "organiser": "Soo-man Lee",
    "organiser_affiliation": "Key Producer & Visionary Leader at A2O Entertainment",
    "organiser_bio": "Born in 1952, Soo-man Lee made his musical debut as part of the duet April and May (4\uc6d4\uacfc 5\uc6d4) in 1971. He began his solo career in 1974 and was honored with the MBC Top 10 Singer Award in 1977. In 1978, he earned his bachelor's degree from Seoul National University. In 1980, he became a prominent media figure, hosting MBC Radio's Starry Night (\ubcc4\uc774 \ube5b\ub098\ub294 \ubc24\uc5d0) and the MBC TV talk show With Soo-man Lee (\uc774\uc218\ub9cc\uacfc \ud568\uaed8). He later pursued graduate studies in the United States, earning a master's degree in Computer Engineering from California State University, Northridge in 1985. In 1989, he founded SM Planning, which evolved into SM Entertainment Co., Ltd. in 1995. Under his leadership, SM debuted its first idol group, H.O.T., in 1996, followed by the debut of solo artist BoA in 2000. He went on to produce and debut leading K-pop acts such as TVXQ, Girls' Generation, EXO, NCT, and aespa, shaping the foundation of the modern K-pop industry. His contributions have been recognized with numerous honors, including the Korea Entertainment Arts Development Award (2005), the Producer Award at the Golden Disc Awards (2008), the Order of Cultural Merit (2011), and Asia's Best Producer at the Top Chinese Music Awards (2016). He was also appointed Honorary Ambassador of Los Angeles in 2005 and awarded the 'Commanderie de Bontemps' honor from Ch\u00e2teau Mouton Rothschild in 2009. Internationally, he was selected for 'Variety 500' by Variety (USA) (2017\u20132020) and Billboard's Impact List (2020). Domestically, he received the K-Pop Contribution Award at the Gaon Chart Music Awards (2021). From 2022 to 2024, he served as Visiting Distinguished Professor in the Department of Computer Science at KAIST. In 2024, he founded A2O Entertainment, continuing his influence as one of the most prominent producers and entrepreneurs in global entertainment.",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "13:00",
    "title": "Keynote-1: Soo-man Lee on \"Culture Technology in the Age of AI\"",
    "uid": "15",
    "web_link": ""
  },
  {
    "category": "Social",
    "channel_url": "",
    "day": "2",
    "description": "",
    "end_time": "14:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "14:00",
    "title": "coffee",
    "uid": "16",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "2",
    "description": "",
    "end_time": "16:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "14:30",
    "title": "Oral Session - 2",
    "uid": "17",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "2",
    "description": "",
    "end_time": "17:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "16:00",
    "title": "Poster Session - 2",
    "uid": "18",
    "web_link": ""
  },
  {
    "category": "Industry",
    "channel_url": "",
    "day": "2",
    "description": "",
    "end_time": "18:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "17:30",
    "title": "Industry Meetup",
    "uid": "19",
    "web_link": ""
  },
  {
    "category": "Music",
    "channel_url": "",
    "day": "2",
    "description": "",
    "end_time": "21:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-22",
    "start_time": "19:30",
    "title": "ISMIR Music Program",
    "uid": "20",
    "web_link": ""
  },
  {
    "category": "Registration",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "9:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "8:00",
    "title": "Registration",
    "uid": "21",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "10:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "9:00",
    "title": "Oral Session - 3",
    "uid": "22",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "12:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "10:30",
    "title": "coffee + Poster Session - 3",
    "uid": "23",
    "web_link": ""
  },
  {
    "category": "Lunch",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "13:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "12:00",
    "title": "Lunch",
    "uid": "24",
    "web_link": ""
  },
  {
    "category": "All Meeting",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "14:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "13:00",
    "title": "Industry Session",
    "uid": "25",
    "web_link": ""
  },
  {
    "category": "Social",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "14:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "14:00",
    "title": "coffee",
    "uid": "26",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "16:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "14:30",
    "title": "Oral Session - 4",
    "uid": "27",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "17:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "16:00",
    "title": "Poster Session - 4",
    "uid": "28",
    "web_link": ""
  },
  {
    "category": "Industry",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "18:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "17:30",
    "title": "WIMIR Session",
    "uid": "29",
    "web_link": ""
  },
  {
    "category": "Music",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "19:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "18:30",
    "title": "K-Culture Night",
    "uid": "30",
    "web_link": ""
  },
  {
    "category": "Music",
    "channel_url": "",
    "day": "3",
    "description": "",
    "end_time": "20:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-23",
    "start_time": "19:30",
    "title": "Korean Traditional Music Concert",
    "uid": "31",
    "web_link": ""
  },
  {
    "category": "Registration",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "9:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "8:00",
    "title": "Registration",
    "uid": "32",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "10:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "9:00",
    "title": "Oral Session - 5",
    "uid": "33",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "12:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "10:30",
    "title": "coffee + Poster Session - 5",
    "uid": "34",
    "web_link": ""
  },
  {
    "category": "Lunch",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "13:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "12:00",
    "title": "Lunch",
    "uid": "35",
    "web_link": ""
  },
  {
    "category": "All Meeting",
    "channel_url": "",
    "day": "4",
    "description": "Koreans cry in the mode of their local folk music. When they are sad and unable to accept a situation, they cry using only certain notes. As they gradually come to terms with reality and reach acceptance or compromise, additional notes are introduced. These shifts in tone reflect emotional transitions embedded in the act of crying. Among traditional Korean musical genres, <b>pansori</b> is a form in which a solo performer narrates an epic story while expressing a wide range of human emotions through music. In pansori, emotional textures\u2014such as denial, anger, sadness, and acceptance\u2014are musically distinct and vividly realized. Listeners who share the same musical and cultural context often experience deep emotional resonance and immersion. This presentation examines how Korean music conveys emotion through the musical language of crying. By analyzing the musical and linguistic elements associated with different emotional states, we explore how sound operates as a shared emotional language in Korean tradition.",
    "end_time": "14:00",
    "image": "hey-jung_kim.jpg",
    "organiser": "Hey-Jung Kim",
    "organiser_affiliation": "Musicologist & Professor at Gyeongin National University of Education",
    "organiser_bio": "Dr. Hey-Jung Kim (Professor, Master of Music, Ph.D. in Literature) is a musicologist and the current president of the Pansori Society. She previously served as president of the Society for Korean Folk Songs. In her role as professor at Gyeongin National University of Education, she is dedicated to training future elementary music educators while simultaneously working to preserve and revitalize traditional Korean culture. Since the 1990s, Dr. Kim has documented and analyzed orally transmitted musical traditions such as Korean folk songs (minyo), nongak (farmer's music), and shamanic rituals. Her research explores the fluid and evolving nature of oral music traditions. Drawing upon extensive field data, she applies statistical and analytical methodologies to uncover the underlying principles of musical language. Her work involves the complex process of locating informants, recording traditional music, transcribing it into notation, and analyzing it. Because individual performers interpret each song differently, large-scale data analysis is crucial in identifying musical universals. Dr. Kim's contributions to the field have been widely recognized through academic citations and prestigious awards.",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "13:00",
    "title": "Keynote-2: Hey-Jung Kim on \"Crying, Language, and Song in Korea: From Folk Songs to Pansori\"",
    "uid": "36",
    "web_link": ""
  },
  {
    "category": "Social",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "14:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "14:00",
    "title": "coffee",
    "uid": "37",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "16:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "14:30",
    "title": "Oral Session - 6",
    "uid": "38",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "17:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "16:00",
    "title": "Poster Session - 6",
    "uid": "39",
    "web_link": ""
  },
  {
    "category": "Industry",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "18:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "17:30",
    "title": "Special Session",
    "uid": "40",
    "web_link": ""
  },
  {
    "category": "Social",
    "channel_url": "",
    "day": "4",
    "description": "",
    "end_time": "21:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-24",
    "start_time": "19:30",
    "title": "Banquet + Jam Session",
    "uid": "41",
    "web_link": ""
  },
  {
    "category": "Registration",
    "channel_url": "",
    "day": "5",
    "description": "",
    "end_time": "9:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "8:00",
    "title": "Registration",
    "uid": "42",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "5",
    "description": "",
    "end_time": "10:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "9:00",
    "title": "Oral Session - 7",
    "uid": "43",
    "web_link": ""
  },
  {
    "category": "Poster session",
    "channel_url": "",
    "day": "5",
    "description": "",
    "end_time": "12:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "10:30",
    "title": "coffee + Poster Session - 7",
    "uid": "44",
    "web_link": ""
  },
  {
    "category": "Lunch",
    "channel_url": "",
    "day": "5",
    "description": "",
    "end_time": "13:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "12:00",
    "title": "Lunch",
    "uid": "45",
    "web_link": ""
  },
  {
    "category": "All Meeting",
    "channel_url": "",
    "day": "5",
    "description": "",
    "end_time": "14:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "13:00",
    "title": "Society Meeting / Board Election",
    "uid": "46",
    "web_link": ""
  },
  {
    "category": "All Meeting",
    "channel_url": "",
    "day": "5",
    "description": "",
    "end_time": "14:30",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "14:00",
    "title": "Award and Test-of-time Talks",
    "uid": "47",
    "web_link": ""
  },
  {
    "category": "All Meeting",
    "channel_url": "",
    "day": "5",
    "description": "",
    "end_time": "15:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "14:30",
    "title": "Closing Remarks, ISMIR 2026",
    "uid": "48",
    "web_link": ""
  },
  {
    "category": "LBD",
    "channel_url": "",
    "day": "5",
    "description": "The Late-breaking/Demo (LBD) session is a forum for sharing prototype systems, initial concepts, and early results which may have not yet fully matured but are of interest to the Music-IR community. It is also a great entry point for people who are new to ISMIR to showcase their preliminary work and receive early feedback from fellow researchers. Attendees of the LBD can interact with demos or discuss their thoughts on the latest developments in the field.",
    "end_time": "17:00",
    "image": "",
    "organiser": "Session Chairs: LBD Session Chairs",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "15:00",
    "title": "Late-breaking/Demo",
    "uid": "49",
    "web_link": ""
  },
  {
    "category": "Social",
    "channel_url": "",
    "day": "5",
    "description": "",
    "end_time": "18:00",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "2025-09-25",
    "start_time": "17:00",
    "title": "Unconference",
    "uid": "50",
    "web_link": ""
  },
  {
    "category": "",
    "channel_url": "",
    "day": "",
    "description": "",
    "end_time": "",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "",
    "start_time": "",
    "title": "",
    "uid": "51",
    "web_link": ""
  },
  {
    "category": "",
    "channel_url": "",
    "day": "",
    "description": "",
    "end_time": "",
    "image": "",
    "organiser": "",
    "organiser_affiliation": "",
    "organiser_bio": "",
    "organiser_emails": "",
    "slack_channel": "",
    "start_date": "",
    "start_time": "",
    "title": "",
    "uid": "52",
    "web_link": ""
  }
]
