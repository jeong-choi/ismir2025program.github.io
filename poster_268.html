


<!DOCTYPE html>
<html lang="en">
  <head>
    


    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />

    <link rel="icon" type="image/png" sizes="32x32" href="static/images/ismir_tab_icon.png">

    <link rel="stylesheet" href="static/css/main.css" />
    <link rel="stylesheet" href="static/css/custom.css" />
    <link rel="stylesheet" href="static/css/lazy_load.css" />
    <link rel="stylesheet" href="static/css/typeahead.css" />
    <link rel="stylesheet" href="static/css/poster.css" />
    <link rel="stylesheet" href="static/css/music.css" />
    <link rel="stylesheet" href="static/css/piece.css" />


    <!-- <link rel="stylesheet" href="https://gitcdn.xyz/repo/wingkwong/jquery-chameleon/master/src/chameleon.min.css"> -->

    <!-- External Javascript libs  -->
    <script src="https://cdn.jsdelivr.net/npm/d3@5/dist/d3.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"
    ></script>


    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script>
    <!-- <script src="static/js/chameleon.js"></script> -->


    <!-- Library libs -->
    <script src="static/js/typeahead.bundle.js"></script>

    

    <!-- External CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous">

    <!-- External Fonts (no google for china) -->
    <link
      href="static/css/Lato.css"
      rel="stylesheet"
    />
    <link href="static/css/Exo.css" rel="stylesheet" />
    <link
      href="static/css/Cuprum.css"
      rel="stylesheet"
    />
    <link
      href="static/css/Ambiant.css"
      rel="stylesheet"
    />
    <!-- <link href="static/css/chameleon.css" rel="stylesheet"/> -->
    <title>ISMIR 2025: From Discord to Harmony: Decomposed Consonance-based Training for Improved Audio Chord Estimation</title>
    
<meta name="citation_title" content="From Discord to Harmony: Decomposed Consonance-based Training for Improved Audio Chord Estimation" />

<meta name="citation_author" content="Andrea Poltronieri" />

<meta name="citation_author" content="Xavier Serra" />

<meta name="citation_author" content="Martín Rocamora" />

<meta name="citation_publication_date" content="21-25 September 2025" />
<meta name="citation_conference_title" content="Ismir 2025 Hybrid Conference" />
<meta name="citation_inbook_title" content="Proceedings of the First MiniCon Conference" />
<meta name="citation_abstract" content="Audio Chord Estimation (ACE) holds a pivotal role in music information research, having garnered attention for over two decades due to its relevance for music transcription and analysis. Despite notable advancements, challenges persist in the task, particularly concerning unique characteristics of harmonic content, which have resulted in existing systems&#39; performances reaching a glass ceiling. These challenges include annotator subjectivity, where varying interpretations among annotators lead to inconsistencies, and class imbalance within chord datasets, where certain chord classes are over-represented compared to others, posing difficulties in model training and evaluation. As a first contribution, this paper presents an evaluation of inter-annotator agreement in chord annotations, using metrics that extend beyond traditional binary measures. In addition, we propose a consonance-informed distance metric that reflects the perceptual similarity between harmonic annotations. Our analysis suggests that consonance-based distance metrics more effectively capture musically meaningful agreement between annotations. Expanding on these findings, we introduce a novel ACE conformer-based model that integrates consonance concepts into the model through consonance-based label smoothing. The proposed model also addresses class imbalance by separately estimating root, bass, and all note activations, enabling the reconstruction of chord labels from decomposed outputs.&lt;br&gt;&lt;br&gt; &lt;b&gt;&lt;p align=&#34;center&#34;&gt;[Direct link to video]()&lt;/b&gt;" />

<meta name="citation_keywords" content="Knowledge-driven approaches to MIR" />

<meta name="citation_keywords" content="Harmony, chords and tonality" />

<meta name="citation_keywords" content="Musical features and properties" />

<meta name="citation_keywords" content="Music transcription and annotation" />

<meta name="citation_keywords" content="Machine learning/artificial intelligence for music" />

<meta name="citation_keywords" content="Computational music theory and musicology" />

<meta name="citation_keywords" content="MIR tasks" />

<meta name="citation_pdf_url" content="" />
<meta id="yt-id" data-name= />
<meta id="bb-id" data-name= />


  </head>

  <body>
    <!-- NAV -->
    
    <!--

    ('tutorials.html', 'Tutorials'),
    ('index.html, 'Home'),
    ('special_meetings.html', 'Special Meetings'),
    -->

    <nav
      class="navbar sticky-top navbar-expand-lg navbar-light mr-auto"
      id="main-nav"
    >
      <div class="container">
        <a class="navbar-brand" href="https://ismir2025.ismir.net">
          <img
             class="logo" src="static/images/ismir_tabicon.png"
             height="auto"
             width="300px"
          />
        </a>
        
        <button
          class="navbar-toggler"
          type="button"
          data-toggle="collapse"
          data-target="#navbarNav"
          aria-controls="navbarNav"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div
          class="collapse navbar-collapse text-right flex-grow-1"
          id="navbarNav"
        >
          <ul class="navbar-nav ml-auto">
            
            <li class="nav-item ">
              <a class="nav-link" href="calendar.html">Schedule</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="papers.html">Papers</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="music.html">Music</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="lbds.html">LBDs</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="industry.html?session=Platinum">Industry</a>
            </li>
            
            <li class="nav-item ">
              <a class="nav-link" href="jobs.html">Jobs</a>
            </li>
            
          </ul>
        </div>
      </div>
    </nav>
    

    
    <!-- User Overrides -->
     

    <div class="container">
      <!-- Tabs -->
      <div class="tabs">
         
      </div>
      <!-- Content -->
      <div class="content">
        

<!-- Title -->
<div class="pp-card m-3" style="">
  <div class="card-header">
    <h2 class="card-title main-title text-center" style="">
      P4-15: From Discord to Harmony: Decomposed Consonance-based Training for Improved Audio Chord Estimation
    </h2>
    <h3 class="card-subtitle mb-2 text-muted text-center">
      
      <a href="papers.html?filter=authors&search=Andrea Poltronieri" class="text-muted"
        >Andrea Poltronieri</a
      >,
      
      <a href="papers.html?filter=authors&search=Xavier Serra" class="text-muted"
        >Xavier Serra</a
      >,
      
      <a href="papers.html?filter=authors&search=Martín Rocamora" class="text-muted"
        >Martín Rocamora</a
      >
      
    </h3>
    <p class="card-text text-center">
      <span class="">Subjects:</span>
      
      <a
        href="papers.html?filter=keywords&search=Knowledge-driven approaches to MIR"
        class="text-secondary text-decoration-none"
        >Knowledge-driven approaches to MIR</a
      > ; 
      
      <a
        href="papers.html?filter=keywords&search=Harmony, chords and tonality"
        class="text-secondary text-decoration-none"
        >Harmony, chords and tonality</a
      > ; 
      
      <a
        href="papers.html?filter=keywords&search=Musical features and properties"
        class="text-secondary text-decoration-none"
        >Musical features and properties</a
      > ; 
      
      <a
        href="papers.html?filter=keywords&search=Music transcription and annotation"
        class="text-secondary text-decoration-none"
        >Music transcription and annotation</a
      > ; 
      
      <a
        href="papers.html?filter=keywords&search=Machine learning/artificial intelligence for music"
        class="text-secondary text-decoration-none"
        >Machine learning/artificial intelligence for music</a
      > ; 
      
      <a
        href="papers.html?filter=keywords&search=Computational music theory and musicology"
        class="text-secondary text-decoration-none"
        >Computational music theory and musicology</a
      > ; 
      
      <a
        href="papers.html?filter=keywords&search=MIR tasks"
        class="text-secondary text-decoration-none"
        >MIR tasks</a
      > 
      
    </p>
    <h4 class="text-muted text-center">
      Presented In-person, in Daejeon
    </h4>
    <h4 class="text-muted text-center">
      
        4-minute short-format presentation
      
    </h4>

  </div>
</div>
<div style="display: flex; justify-content: center;" class="btn-toolbar mt-4" role="toolbar">
  <div class="poster-buttons btn-group btn-group-toggle mb-3" data-toggle="buttons">
    <button class="card-link btn btn-outline-primary" data-toggle="collapse" type="button" data-target="#details">
      Abstract
    </button>
    <button class="card-link btn btn-outline-primary" data-toggle="collapse" type="button" data-target="#paper">
      Paper
    </button>
    <button class="card-link btn btn-outline-primary" data-toggle="collapse" type="button" data-target="#poster">
      Poster
    </button>
    <button class="card-link btn btn-outline-primary" data-toggle="collapse" type="button" data-target="#video">
      Video
    </button>
    
      <button class="card-link btn btn-outline-primary" data-toggle="collapse" type="button" data-target="#meta-review">
        Meta
      </button>
      <button class="card-link btn btn-outline-primary" data-toggle="collapse" type="button" data-target="#review1">
        R1
      </button>
      <button class="card-link btn btn-outline-primary" data-toggle="collapse" type="button" data-target="#review2">
        R2
      </button>
      
        <button class="card-link btn btn-outline-primary" data-toggle="collapse" type="button" data-target="#review3">
          R3
        </button>
      
    
    <!--  -->
  </div>
  
</div>
<div class="poster-content">
  <div id="details" class="pp-card m-3 collapse">
    <div class="card-body">
      <div class="card-text">
        <div id="abstractExample">
          <span class="font-weight-bold">Abstract:</span>
          <p>Audio Chord Estimation (ACE) holds a pivotal role in music information research, having garnered attention for over two decades due to its relevance for music transcription and analysis. Despite notable advancements, challenges persist in the task, particularly concerning unique characteristics of harmonic content, which have resulted in existing systems' performances reaching a glass ceiling. These challenges include annotator subjectivity, where varying interpretations among annotators lead to inconsistencies, and class imbalance within chord datasets, where certain chord classes are over-represented compared to others, posing difficulties in model training and evaluation. As a first contribution, this paper presents an evaluation of inter-annotator agreement in chord annotations, using metrics that extend beyond traditional binary measures. In addition, we propose a consonance-informed distance metric that reflects the perceptual similarity between harmonic annotations. Our analysis suggests that consonance-based distance metrics more effectively capture musically meaningful agreement between annotations. Expanding on these findings, we introduce a novel ACE conformer-based model that integrates consonance concepts into the model through consonance-based label smoothing. The proposed model also addresses class imbalance by separately estimating root, bass, and all note activations, enabling the reconstruction of chord labels from decomposed outputs.<br><br> <b><p align="center"><a href="">Direct link to video</a></b></p>
        </div>
      </div>
      <p></p>
    </div>
  </div>
  <div id="paper" class="collapse">
    
    <button class="fullscreen-button btn btn-primary mb-3">Fullscreen</button>
    <iframe class="fullscreen-iframe" src = "https://drive.google.com/file/d/1rGtA51MVnEBY0Ea0U61OfGG_Jhwiax6F/preview#embedded=true" width='100%' height='500px' allowfullscreen webkitallowfullscreen></iframe>
    
  </div>
  <div id="poster" class="collapse">
    
    <button class="fullscreen-button btn btn-primary mb-3">Fullscreen</button>
    <iframe class="fullscreen-iframe" src = "#embedded=true" width='100%' height='500px' allowfullscreen webkitallowfullscreen></iframe>
    
  </div>
  <div id="video" class="collapse">
    
      <div  style="display: flex; justify-content: center;">
      <iframe src="" width="960" height="540" allow="encrypted-media" allowfullscreen></iframe>
      </div>
    
  </div>
  
  <div id="meta-review" class="pp-card m-3 collapse">
    <div class="card-body">
      <div class="card-text">
        <div id="metaReviewExample">
          <span class="font-weight-bold">Meta Review:</span>
          <br>
          <p><strong>Q2 ( I am an expert on the topic of the paper.)</strong></p>
<p>Strongly agree</p>
<p><strong>Q3 ( The title and abstract reflect the content of the paper.)</strong></p>
<p>Agree</p>
<p><strong>Q4 (The paper discusses, cites and compares with all relevant related work.)</strong></p>
<p>Agree</p>
<p><strong>Q6 (Readability and paper organization: The writing and language are clear and structured in a logical manner.)</strong></p>
<p>Agree</p>
<p><strong>Q7 (The paper adheres to ISMIR 2025 submission guidelines (uses the ISMIR 2025 template, has at most 6 pages of technical content followed by “n” pages of references or ethical considerations, references are well formatted). If you selected “No”, please explain the issue in your comments.)</strong></p>
<p>Yes</p>
<p><strong>Q8 (Relevance of the topic to ISMIR: The topic of the paper is relevant to the ISMIR community. Note that submissions of novel music-related topics, tasks, and applications are highly encouraged. If you think that the paper has merit but does not exactly match the topics of ISMIR, please do not simply reject the paper but instead communicate this to the Program Committee Chairs. Please do not penalize the paper when the proposed method can also be applied to non-music domains if it is shown to be useful in music domains.)</strong></p>
<p>Strongly agree</p>
<p><strong>Q9 (Scholarly/scientific quality: The content is scientifically correct.)</strong></p>
<p>Agree</p>
<p><strong>Q11 (Novelty of the paper: The paper provides novel methods, applications, findings or results. Please do not narrowly view "novelty" as only new methods or theories. Papers proposing novel musical applications of existing methods from other research fields are considered novel at ISMIR conferences.)</strong></p>
<p>Strongly agree</p>
<p><strong>Q12 (The paper provides all the necessary details or material to reproduce the results described in the paper. Keep in mind that ISMIR respects the diversity of academic disciplines, backgrounds, and approaches. Although ISMIR has a tradition of publishing open datasets and open-source projects to enhance the scientific reproducibility, ISMIR accepts submissions using proprietary datasets and implementations that are not sharable. Please do not simply reject the paper when proprietary datasets or implementations are used.)</strong></p>
<p>Agree</p>
<p><strong>Q13 (Pioneering proposals: This paper proposes a novel topic, task or application. Since this is intended to encourage brave new ideas and challenges, papers rated “Strongly Agree” and “Agree” can be highlighted, but please do not penalize papers rated “Disagree” or “Strongly Disagree”. Keep in mind that it is often difficult to provide baseline comparisons for novel topics, tasks, or applications. If you think that the novelty is high but the evaluation is weak, please do not simply reject the paper but carefully assess the value of the paper for the community.)</strong></p>
<p>Agree (Novel topic, task, or application)</p>
<p><strong>Q14 (Reusable insights: The paper provides reusable insights (i.e. the capacity to gain an accurate and deep understanding). Such insights may go beyond the scope of the paper, domain or application, in order to build up consistent knowledge across the MIR community.)</strong></p>
<p>Agree</p>
<p><strong>Q15 (Please explain your assessment of reusable insights in the paper.)</strong></p>
<p>The perceptually motivated approach this work takes could instigate similar research in other problems where hard labels seemingly present a performance ceiling.</p>
<p><strong>Q16 ( Write ONE line (in your own words) with the main take-home message from the paper.)</strong></p>
<p>A conformer-based model using label smoothing and a consonance-based evaluation metric shows strong promise for ACE.</p>
<p><strong>Q17 (This paper is of award-winning quality.)</strong></p>
<p>No</p>
<p><strong>Q19 (Potential to generate discourse: The paper will generate discourse at the ISMIR conference or have a large influence/impact on the future of the ISMIR community.)</strong></p>
<p>Strongly agree</p>
<p><strong>Q20 (Overall evaluation (to be completed before the discussion phase): Please first evaluate before the discussion phase. Keep in mind that minor flaws can be corrected, and should not be a reason to reject a paper. Please familiarize yourself with the reviewer guidelines at https://ismir.net/reviewer-guidelines.)</strong></p>
<p>Weak accept</p>
<p><strong>Q21 (Main review and comments for the authors (to be completed before the discussion phase). Please summarize strengths and weaknesses of the paper. It is essential that you justify the reason for the overall evaluation score in detail. Keep in mind that belittling or sarcastic comments are not appropriate.)</strong></p>
<p>The presented work uses non-binary distance measures to model inter-annotator agreements together with consonance-based label smoothing as a means to train an audio chord estimation (ACE) model. This is interesting and multidimensional work with compelling results that will receive interest from the research community. </p>
<p>Authors introduce a perceptually-informed distance metric, in the context of Western music, that models the agreement between annotators in a musically meaningful way. They first define Mechanical Distance which quantifies the magnitude of deviation for each incorrect note from the target chord and by combining it with consonance they arrive at the Mechanical-Consonance metric which weighs each semitone deviation according to its perceptual consonance value. This metric achieves a higher inter-annotator agreement score and has better discriminative ability with respect to random data.</p>
<p>The proposed model contains an acoustic front-end followed by a conformer model which combines CNN and transformer models to capture local and global dependencies. Three fully-connected layers are then used to predict bass, root, and chord pitch class content all from which a symbolic prediction is made after label smoothing where more consonant intervals receive higher similarity scores.</p>
<p>Evaluation is performed on standard datasets which reveal better performance compared to the BTC model. They also provide a simple analysis of the penultimate layer activations with and without consonance smoothing. All in all, the competitive results show the viability of the approach and this work will set a significant benchmark for ACE going forward.</p>
<p>The paper presents a novel approach and provides valuable insights into how to leverage the level of agreement of annotated data and label smoothing in a musically meaningful way toward improving ACE. It is well-written for the most part with strong motivation and literature review however since there are many different issues the paper tackles space seems to be tight. It would be beneficial for the authors to make another pass in order to make space for implementation details and include some additional results as suggested by the reviewers for improving the presentation. Please go through the references and format them properly (e.g. [35], [38]).</p>
<p><strong>Q22 (Final recommendation (to be completed after the discussion phase) Please give a final recommendation after the discussion phase. In the final recommendation, please do not simply average the scores of the reviewers. Note that the number of recommendation options for reviewers is different from the number of options here. We encourage you to take a stand, and preferably avoid “weak accepts” or “weak rejects” if possible.)</strong></p>
<p>Accept</p>
<p><strong>Q23 (Meta-review and final comments for authors (to be completed after the discussion phase))</strong></p>
<p>All reviewers have provided positive feedback about this work and are in agreement that the ISMIR community will benefit from publication of the paper. It contains useful insights into chord estimation and will be of interest to researchers working in this field. Please carefully address the issues raised by the reviewers (especially those from reviewers #2 and #3) in the final form of the paper prior to submission for publication. Since there is limited space you will need to be creative in compressing the existing content to insert the new informational and clarifying text that we are asking. Please remember to go through your references to ensure consistency and adherence to the required format.</p>
        </div>
      </div>
    </div> 
  </div>
  <div id="review1" class="pp-card m-3 collapse">
    <div class="card-body">
      <div class="card-text">
        <div id="review1Example">
          <span class="font-weight-bold">Review 1:</span>
          <br>
          <ul>
<li><strong>Overall Evaluation</strong>: Weak accept</li>
</ul>
<h4>Main Reviews</h4>
<p>This paper improves audio chord estimation by proposing a new Mech-Cons metric to better capture the chord relationships beyond the traditional binary one, which is then incorporated as consonance-based smoothing for the better estimation performances. </p>
<p>Although the improvements of the model architecture seem incremental, I really appreciate the discussion of harmonic subjectivity/ambiguity by investigating inter-rater agreement in depth, which results in a new Mech-Cons metric to better reflect the chord relationships beyond the binary metric. This metric can be used in other future research regarding chords and harmony. </p>
<p>The formatting of references can be better. For example, the page number for [4] is missing, and some entries provide online links while others don't. I suggest using a unified reference style. Furthermore, the important information of the dataset split in Section 4 is missing out, which should be added and specified in the final version. The performances of the BTC model do not coincide with the ones proposed in the original paper, so I assume the authors let BTC infer on their test set. Please make sure this is the case (and also make sure the author's test set do not overlap with any training data of the original BTC), and provide corresponding explanations in the text.</p>
<p>Overall, this is a valid piece of work on audio chord estimation. I will accept this paper.</p>
        </div>
      </div>
    </div> 
  </div>
  <div id="review2" class="pp-card m-3 collapse">
    <div class="card-body">
      <div class="card-text">
        <div id="review2Example">
          <span class="font-weight-bold">Review 2:</span>
          <br>
          <ul>
<li><strong>Overall Evaluation</strong>: Weak accept</li>
</ul>
<h4>Main Reviews</h4>
<p>The paper considers two important challenges in automatic chord estimation (ACE): class imbalance and annotation subjectivity. The paper proposes
1) (to tackle the subjectivity) Mechanical-Consonance metric (Mech-Cons) for evaluation, which takes the consonance relationship between pitches into consideration,
2) A Conformer-based ACE model that predicts root, bass and pitch and then decodes these information into chord symbols, and
3) (to tackle the imbalance) consonance-based label smoothing (LS) that penalizes the musically meaningful errors less
Results show that the proposed Mech-Cons metric achieves higher inter-annotator agreement score, which means it is able to capture the ambiguity between different chords. The proposed model outperforms BTC, a strong ACE baseline, and the consonance-based LS further improves the performance, both in terms of standard mir_eval metrics and the proposed Mech-Cons.</p>
<p>Strengths
- The Mech-Cons metric that authors propose show higher inter-ratter agreement than other metrics, especially the standard MIREX metric, which means that Mech-Cons better captures humans’ subjectivity in chord annotations.
- The proposed model is novel. While the authors do not point out or do any further study, the process of predicting bass, root and pitch classes and then decode them to chord labels is new. Note that it is different from [12] where there is a trainable linear layer to predict the chord label from these information.
- The proposed consonance-based smoothing improves the performance of the system, both in terms of standard MIREX scores and Mech-Cons.</p>
<p>Weaknesses and Questions
- I think it is good work but the presentation can be improved to make it clearer. I understand that due to page limit, there are many things that the authors don’t have space to explain in detail (e.g. TbT, mechanical distance and section 4.2, specified below), but the lack of explanation adds to the difficulty of reading.
- Table 1 should include binary agreement since it is something the authors explicitly mention to compare to. Here, TbT and Mech are proposed in [10] and is (I believe) less familiar to the community compared to MIREX score. However, the authors use minimal effort to explain what TbT and (in particular) Mech are. Mech serves as the basis of the proposed Mech-Cons, and this significantly adds to the difficulty of reading. E.g. why we can use the consonance vector as a parameter.
- Section 4.1 and Table 3 are the main results for the model-wise contribution. (2 and 3 in the summary above) However, this is too fast, especially for the label-smoothing technique. To show that LS improves the model’s performance, we also need to see BTC with linear LS and consonance LS, otherwise it is reasonable to doubt that LS work only with the conformer model. Also, it is intuitive that consonance works the best with Mech-Cons because they share similar targets. Would authors agree with that?
- The authors let the model predict bass, root and pitches and then use a separate decoder to convert them into chord labels. This is done by neither [12] nor BTC. It is still a fair comparison if the baseline BTC is also implemented in this way but the effect of such uncommon implementation is not investigated.
- Section 4.2 seems a bit incomprehensive due to the limited space. The authors say that “Consonance-based smoothing promotes equidistance…” (Line 483-485) However, this is not correct. [11] claims that LS encourages equidistance because [11] uses the standard LS (linear, in this paper’s words), but since the authors uses a different, delicately designed, consonance-based LS, we should expect something different. To make the whole section 4.2 stronger, we need to compare the representation of No LS, linear LS and consonance LS, and also not only semitone-based “C-C#-D” but probably also fifth-based “C-G-D”.</p>
<p>Overall, I think this paper covers many, and even too many contents, including evaluation metric, improving from BTC to Conformer, training with label smoothing, each of which is probably worth writing a separate paper, especially the evaluation metrics. I greatly appreciate that the authors, based on their comprehensive literature review, have put together everything and proposed the strong model. However, squeezing everything into a paper means some discussions have to be on a superficial level and bring limited insights.
I would recommend a weak accept. If the paper is accepted, I would suggest considering the weaknesses and questions mentioned above and focus on only the essential parts of their work in the paper (e.g. Get rid of line 223-240 and give more explanation about basic mechanical distance).</p>
<p>Minor corrections: 
- Put Figure 1 in the same page as 3.2
- Some of the references are not properly formatted. For example, [15] is published in ICASSP. Many papers are from ISMIR but are formatted differently, e.g. [4], [5], [6] and [14]. If the paper is accepted the authors should clean the references.</p>
        </div>
      </div>
    </div> 
  </div>
  
    <div id="review3" class="pp-card m-3 collapse">
      <div class="card-body">
        <div class="card-text">
          <div id="review3Example">
            <span class="font-weight-bold">Review 3:</span>
            <br>
            <ul>
<li><strong>Overall Evaluation</strong>: Weak accept</li>
</ul>
<h4>Main Reviews</h4>
<p>This paper proposes a novel conformer-based model for Audio Chord Estimation (ACE), enhanced with a consonance-based label smoothing technique. It aims to address persistent challenges in ACE by leveraging perceptually informed metrics and smoothing strategies grounded in music theory.</p>
<p>Strengths
• Clarity and Structure
The paper is well-written, with a clear structure that makes it easy to follow. The motivation is well-established, and the progression from problem identification to solution and evaluation is logically organized.</p>
<p>• Innovative Use of Consonance-based Smoothing
The introduction of consonance-based label smoothing is both novel and musically meaningful. The authors make a compelling case for how this method aligns better with human perception than traditional binary or uniform smoothing techniques.</p>
<p>Weaknesses and Suggestions
1. Lack of Detail on Data Splits: The paper does not explain how the training, validation, and test sets were divided. This information is critical for reproducibility and should be clearly stated, including whether any cross-validation was performed or how the validation set was selected.
2. Since the reported performance improvements are relatively marginal in some metrics, it would strengthen the empirical claims if standard deviations were included.
3. Unclear BTC Evaluation Procedure: The paper compares the proposed model to the BTC model [24] in Table 3, but it is not clear whether the BTC results were reproduced using the original model weights, retrained under the same setup, or reimplemented. Clarifying this is essential for interpreting the fairness and reliability of the comparison.
4. While BTC is a known method, it differs from the proposed model in both architecture (bidirectional Transformer vs. Conformer) and decoding strategy (BTC lacks the root/bass/pitch-based decoding described in Section 3.4). A more suitable baseline would be the model in [23], which includes a decoding strategy and is publicly available. Comparing against [23] could better isolate the contributions of the conformer architecture versus the decoding mechanism.
5. Although the Mechanical-Consonance metric is well-motivated, it would be beneficial to also test label smoothing using the Tone-by-Tone metric in Table 3. This would provide further empirical grounding for the choice of Mechanical-Consonance smoothing.
6. Justification for Decoding Choice: It would be helpful if the authors provided rationale for adopting the decoding approach from [12] instead of the one from [23], especially since [23] argues that their decoding method offers advantages and is more expressive.</p>
<p>Minor Issues and Typos
• Line 335 / 382: There is inconsistency in English style: “normalisation” (UK) in Line 335 and “normalize” (US) in Line 382. Please standardize the English style throughout the paper.
• Table 3: The best result on the Tetrads metric is achieved by the model with Linear smoothing, but the bold text is mistakenly applied to the Consonance model. Please correct the formatting.</p>
<p>I appreciate the potential of this work and commend the authors for addressing an important challenge in audio chord estimation using a musically meaningful approach. However, due to several unresolved issues in the experimental setup and evaluation, I believe the work would benefit from further clarification and refinement before publication.</p>
          </div>
        </div>
      </div> 
    </div>
  
  
</div>


<script src="static/js/poster.js"></script>
<script src="static/js/video_selection.js"></script>

      </div>
    </div>
    
    

    <!-- Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=UA-"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "UA-");
    </script>

    <!-- Footer -->
    <footer class="footer bg-light p-4">
      <div class="container">
        <p class="float-right"><a href="#">Back to Top</a></p>
        <p class="text-center">© 2023 ISMIR Organization Committee</p>
      </div>
    </footer>

    <!-- Code for hash tags -->
    <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });
      });
    </script>
    <script src="static/js/lazy_load.js"></script>
    
  </body>
</html>